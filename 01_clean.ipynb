{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genderize import Genderize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "apikey = 'f4143e73e7517e9f7ea0f9e8dc62ca52'\n",
    "\n",
    "exportfolder = r\"/group/geog_pyloo/XY/01_gender/_data/_clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  out of  15990  are missing corresponding author info\n",
      "Number of unique first name for first authors:  9436\n",
      "Number of unique first name for corresponding authors:  9241\n",
      "Number of unique first name for corresponding authors not in first authors:  2352\n",
      "Number of names to detect:  10013\n",
      "Processing 10013 names for keyword: living\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [06:06<00:00, 33.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  out of  12156  are missing corresponding author info\n",
      "Number of unique first name for first authors:  6899\n",
      "Number of unique first name for corresponding authors:  6644\n",
      "Number of unique first name for corresponding authors not in first authors:  1670\n",
      "Number of names to detect:  5206\n",
      "Processing 5206 names for keyword: mobility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:13<00:00, 32.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  out of  21850  are missing corresponding author info\n",
      "Number of unique first name for first authors:  12274\n",
      "Number of unique first name for corresponding authors:  11954\n",
      "Number of unique first name for corresponding authors not in first authors:  2450\n",
      "Number of names to detect:  7373\n",
      "Processing 7373 names for keyword: people\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:27<00:00, 33.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  out of  13801  are missing corresponding author info\n",
      "Number of unique first name for first authors:  7483\n",
      "Number of unique first name for corresponding authors:  7395\n",
      "Number of unique first name for corresponding authors not in first authors:  1718\n",
      "Number of names to detect:  4595\n",
      "Processing 4595 names for keyword: economy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [02:54<00:00, 34.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  out of  6255  are missing corresponding author info\n",
      "Number of unique first name for first authors:  3985\n",
      "Number of unique first name for corresponding authors:  3969\n",
      "Number of unique first name for corresponding authors not in first authors:  790\n",
      "Number of names to detect:  0\n",
      "Processing 0 names for keyword: governance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 6853.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  out of  23246  are missing corresponding author info\n",
      "Number of unique first name for first authors:  12687\n",
      "Number of unique first name for corresponding authors:  11994\n",
      "Number of unique first name for corresponding authors not in first authors:  4306\n",
      "Number of names to detect:  8148\n",
      "Processing 8148 names for keyword: environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:00<00:00, 33.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  out of  17172  are missing corresponding author info\n",
      "Number of unique first name for first authors:  9192\n",
      "Number of unique first name for corresponding authors:  8714\n",
      "Number of unique first name for corresponding authors not in first authors:  2374\n",
      "Number of names to detect:  3036\n",
      "Processing 3036 names for keyword: city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:50<00:00, 27.57s/it]\n"
     ]
    }
   ],
   "source": [
    "def get_firstname(x):\n",
    "    xlen = len(x.split(\", \"))\n",
    "    if xlen == 1:\n",
    "        xlen2 = len(x.split(\" \"))\n",
    "        if xlen2 == 1:\n",
    "            return x.strip()\n",
    "        else:\n",
    "            return x.split(\" \")[1].strip()\n",
    "    elif xlen >= 2:\n",
    "        return x.split(\", \")[1].strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_surname(x):\n",
    "    return x.split(\",\")[0].strip()\n",
    "\n",
    "def get_corresponding(row):\n",
    "    if type(row['ORCIDs']) == float:\n",
    "        return row['author_first']\n",
    "    else:\n",
    "        return row['ORCIDs'].split(\"/\")[0]\n",
    "\n",
    "def clean(DF):\n",
    "    DF = DF[DF['Author Full Names'].notnull()].reset_index(drop=True)\n",
    "    DF = DF[DF['Reprint Addresses'].notnull()].reset_index(drop=True)\n",
    "    DF['author_corresponding'] = DF['Reprint Addresses'].apply(lambda x: x.split('(corresponding author)')[0].strip())\n",
    "    DF['author_corresponding_n1'] = DF['author_corresponding'].apply(lambda x: x.split(';')[0].strip())\n",
    "    DF['author_first'] = DF['Author Full Names'].apply(lambda x: x.split(\";\")[0])\n",
    "    DF['author_first_len'] = DF['author_first'].apply(lambda x: len(x.split(\",\")))\n",
    "    DF['author_ls'] = DF['Authors'].apply(lambda x: x.split(\"; \"))\n",
    "    \n",
    "    def get_corresponding(x):\n",
    "        auls = x['Author Full Names'].split(\"; \")\n",
    "        try:\n",
    "            idx = x['author_ls'].index(x['author_corresponding_n1'])\n",
    "            return auls[idx]\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    DF['author_corresponding_full'] = DF.apply(lambda row: get_corresponding(row), axis=1)\n",
    "    DF['author_first'] = DF['Author Full Names'].apply(lambda x: x.split(\";\")[0])\n",
    "    DF['author_first_first_name'] = DF['author_first'].apply(lambda x: get_firstname(x))\n",
    "    DF['author_first_surname'] = DF['author_first'].apply(lambda x: get_surname(x))\n",
    "    print(DF[DF['author_corresponding_full'].isnull()].shape[0], \" out of \", DF.shape[0], \" are missing corresponding author info\")\n",
    "    DF['author_corresponding_full'] = DF['author_corresponding_full'].fillna(DF['author_first'])\n",
    "    DF['author_corresponding_first_name'] = DF['author_corresponding_full'].apply(lambda x: get_firstname(x))\n",
    "    DF['author_corresponding_surname'] = DF['author_corresponding_full'].apply(lambda x: get_surname(x))\n",
    "    return DF\n",
    "\n",
    "def get_remain_names(DF):\n",
    "    namels1 = DF['author_first_first_name'].unique()\n",
    "    print(\"Number of unique first name for first authors: \", len(namels1))\n",
    "    namels2 = DF['author_corresponding_first_name'].unique()\n",
    "    print(\"Number of unique first name for corresponding authors: \", len(namels2))\n",
    "    namels2_no1 = [x for x in namels2 if x not in namels1]\n",
    "    print(\"Number of unique first name for corresponding authors not in first authors: \", len(namels2_no1))\n",
    "    \n",
    "    namels_sent = namels1.tolist() + namels2_no1\n",
    "    \n",
    "    genderize_result_path = os.path.join(exportfolder, \"genderize_result.csv\")\n",
    "    if os.path.exists(genderize_result_path):\n",
    "        finished = pd.read_csv(genderize_result_path)\n",
    "    else:\n",
    "        finished = pd.DataFrame(columns=['name', 'gender', 'probability'])\n",
    "\n",
    "    toadd = [x for x in namels_sent if x not in finished['name'].tolist()]\n",
    "    print(\"Number of names to detect: \", len(toadd))\n",
    "    return toadd, finished\n",
    "\n",
    "\n",
    "def load_and_clean_data(folder, keyword):\n",
    "    files = os.listdir(folder)\n",
    "    DF = []\n",
    "    for f in files:\n",
    "        if f.endswith('.xls') or f.endswith('.xlsx'):\n",
    "            df = pd.read_excel(folder + \"/\" + f)\n",
    "            DF.append(df)\n",
    "    DF = pd.concat(DF).reset_index(drop=True)\n",
    "    DF = clean(DF)\n",
    "    return DF\n",
    "\n",
    "folder_dict = {\n",
    "    #  'ai': '/group/geog_pyloo/XY/01_gender/_data/ai',\n",
    "    'living': '/group/geog_pyloo/XY/01_gender/_data/Smart living',\n",
    "    'mobility': '/group/geog_pyloo/XY/01_gender/_data/Smart mobility',\n",
    "    'people': '/group/geog_pyloo/XY/01_gender/_data/Smart people',\n",
    "    'economy': '/group/geog_pyloo/XY/01_gender/_data/Smart economy',\n",
    "    'governance': '/group/geog_pyloo/XY/01_gender/_data/Smart governance',\n",
    "    'environment': '/group/geog_pyloo/XY/01_gender/_data/Smart environment',\n",
    "    'city': '/group/geog_pyloo/XY/01_gender/_data/Smart city'\n",
    "}\n",
    "\n",
    "genderize = Genderize(\n",
    "    user_agent='GenderizeDocs/0.0',\n",
    "    api_key=apikey,\n",
    "    timeout=5.0)\n",
    "\n",
    "for keyword, folder in folder_dict.items():\n",
    "    DF = load_and_clean_data(folder, keyword)\n",
    "    toadd, finished = get_remain_names(DF)\n",
    "\n",
    "    print(f\"Processing {len(toadd)} names for keyword: {keyword}\")\n",
    "    chucksize = 1000\n",
    "    N = len(toadd) // chucksize + 1\n",
    "    result_ls = []\n",
    "    for i in tqdm(range(N)):\n",
    "        temp = genderize.get(toadd[i*chucksize:(i+1)*chucksize])\n",
    "        result_ls.append(temp)\n",
    "\n",
    "    result_ls2 = []\n",
    "    for i in range(len(result_ls)):\n",
    "        result_ls2 = result_ls2 + result_ls[i]\n",
    "\n",
    "    result = pd.DataFrame(result_ls2).reset_index(drop=True)\n",
    "    result_update = pd.concat([finished, result]).reset_index(drop=True)\n",
    "    result_update.to_csv(os.path.join(exportfolder, \"genderize_result.csv\"), index=False)\n",
    "\n",
    "    result_update = pd.read_csv(os.path.join(exportfolder, \"genderize_result.csv\"))\n",
    "    result_update = result_update[result_update['probability'] >= 0.75]\n",
    "\n",
    "    DF = DF.merge(result_update[['name', 'gender', 'probability']], left_on='author_first_first_name', right_on='name', how='left').rename(columns={'gender': 'gender_first', 'probability': 'probability_first'}).drop(columns=['name'])\n",
    "    DF = DF.merge(result_update[['name', 'gender', 'probability']], left_on='author_corresponding_first_name', right_on='name', how='left').rename(columns={'gender': 'gender_corresponding', 'probability': 'probability_corresponding'}).drop(columns=['name'])\n",
    "\n",
    "    final_columns = [\n",
    "        'Publication Date',\n",
    "        'Journal Abbreviation',\n",
    "        'Publication Year',\n",
    "        'Research Areas',\n",
    "        'Authors',\n",
    "        'Abstract',\n",
    "        'Article Title',\n",
    "        'Author Keywords',\n",
    "        # 'author_corresponding',\n",
    "        # 'author_first',\n",
    "        # 'author_corresponding_full',\n",
    "        # 'author_first_first_name',\n",
    "        # 'author_first_surname',\n",
    "        # 'author_corresponding_first_name',\n",
    "        # 'author_corresponding_surname',\n",
    "        'gender_first',\n",
    "        'probability_first',\n",
    "        'gender_corresponding',\n",
    "        'probability_corresponding'\n",
    "    ]\n",
    "\n",
    "    DF = DF[final_columns]\n",
    "    DF.to_csv(os.path.join(exportfolder, f\"cleandata_{keyword}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "exportfolder = r\"/group/geog_pyloo/XY/01_gender/_data/_clean\"\n",
    "\n",
    "folder_dict = {\n",
    "    'ai': 'cleandata_ai.csv',\n",
    "    'living': 'cleandata_living.csv',\n",
    "    'mobility': 'cleandata_mobility.csv',\n",
    "    'people': 'cleandata_people.csv',\n",
    "    'economy': 'cleandata_economy.csv',\n",
    "    'governance': 'cleandata_governance.csv',\n",
    "    'environment': 'cleandata_environment.csv',\n",
    "    'city': 'cleandata_city.csv'\n",
    "}\n",
    "\n",
    "# 定义性别组合的函数\n",
    "def gender_combination(row):\n",
    "    first = row['gender_first']\n",
    "    corresponding = row['gender_corresponding']\n",
    "    if first == 'female' and corresponding == 'female':\n",
    "        return 'Female only'\n",
    "    elif (first == 'female' and corresponding == 'unknown') or (first == 'unknown' and corresponding == 'female'):\n",
    "        return 'Female & Unknown'\n",
    "    elif first == 'male' and corresponding == 'male':\n",
    "        return 'Male only'\n",
    "    elif (first == 'female' and corresponding == 'male') or (first == 'male' and corresponding == 'female'):\n",
    "        return 'Female & Male'\n",
    "    elif first == 'unknown' and corresponding == 'unknown':\n",
    "        return 'Both Unknown'\n",
    "    elif first == 'unknown' or corresponding == 'unknown':\n",
    "        if first == 'male' or corresponding == 'male':\n",
    "            return 'Male & Unknown'\n",
    "        if first == 'female' or corresponding == 'female':\n",
    "            return 'Female & Unknown'\n",
    "    else:\n",
    "        return 'Non-Analyzable'\n",
    "\n",
    "# 定义新的性别标签函数\n",
    "def gender_label_2(combination):\n",
    "    if combination in ['Female only', 'Female & Unknown', 'Female & Male']:\n",
    "        return 'withFemale'\n",
    "    elif combination == 'Male only':\n",
    "        return 'Male only'\n",
    "    elif combination == 'Both Unknown':\n",
    "        return 'other'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "# 存储结果的字典\n",
    "results = {}\n",
    "\n",
    "# 计算每个关键词的性别比例\n",
    "for keyword, filename in folder_dict.items():\n",
    "    filepath = os.path.join(exportfolder, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    # 将空值填充为'unknown'\n",
    "    df['gender_first'] = df['gender_first'].fillna('unknown')\n",
    "    df['gender_corresponding'] = df['gender_corresponding'].fillna('unknown')\n",
    "    df['gender_combination'] = df.apply(gender_combination, axis=1)\n",
    "    df['gender_label_2'] = df['gender_combination'].apply(gender_label_2)\n",
    "    result = df['gender_combination'].value_counts(normalize=True)\n",
    "    results[keyword] = result\n",
    "    # 保存回原文件\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "# 转换为DataFrame并填充缺失值\n",
    "result_df = pd.DataFrame(results).fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ai</th>\n",
       "      <th>living</th>\n",
       "      <th>mobility</th>\n",
       "      <th>people</th>\n",
       "      <th>economy</th>\n",
       "      <th>governance</th>\n",
       "      <th>environment</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_combination</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Male only</th>\n",
       "      <td>70802</td>\n",
       "      <td>8133</td>\n",
       "      <td>6706</td>\n",
       "      <td>10887</td>\n",
       "      <td>6321</td>\n",
       "      <td>3110</td>\n",
       "      <td>11608</td>\n",
       "      <td>9064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male &amp; Unknown</th>\n",
       "      <td>10950</td>\n",
       "      <td>1080</td>\n",
       "      <td>870</td>\n",
       "      <td>1403</td>\n",
       "      <td>880</td>\n",
       "      <td>262</td>\n",
       "      <td>2428</td>\n",
       "      <td>1478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Both Unknown</th>\n",
       "      <td>14573</td>\n",
       "      <td>1979</td>\n",
       "      <td>1345</td>\n",
       "      <td>3038</td>\n",
       "      <td>1628</td>\n",
       "      <td>556</td>\n",
       "      <td>2329</td>\n",
       "      <td>1750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female only</th>\n",
       "      <td>20441</td>\n",
       "      <td>3353</td>\n",
       "      <td>2130</td>\n",
       "      <td>4727</td>\n",
       "      <td>3584</td>\n",
       "      <td>1770</td>\n",
       "      <td>3687</td>\n",
       "      <td>3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female &amp; Unknown</th>\n",
       "      <td>3082</td>\n",
       "      <td>333</td>\n",
       "      <td>216</td>\n",
       "      <td>431</td>\n",
       "      <td>385</td>\n",
       "      <td>123</td>\n",
       "      <td>705</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Female &amp; Male</th>\n",
       "      <td>11033</td>\n",
       "      <td>1112</td>\n",
       "      <td>889</td>\n",
       "      <td>1364</td>\n",
       "      <td>1003</td>\n",
       "      <td>434</td>\n",
       "      <td>2489</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ai  living  mobility  people  economy  governance  \\\n",
       "gender_combination                                                         \n",
       "Male only           70802    8133      6706   10887     6321        3110   \n",
       "Male & Unknown      10950    1080       870    1403      880         262   \n",
       "Both Unknown        14573    1979      1345    3038     1628         556   \n",
       "Female only         20441    3353      2130    4727     3584        1770   \n",
       "Female & Unknown     3082     333       216     431      385         123   \n",
       "Female & Male       11033    1112       889    1364     1003         434   \n",
       "\n",
       "                    environment  city  \n",
       "gender_combination                     \n",
       "Male only                 11608  9064  \n",
       "Male & Unknown             2428  1478  \n",
       "Both Unknown               2329  1750  \n",
       "Female only                3687  3014  \n",
       "Female & Unknown            705   421  \n",
       "Female & Male              2489  1445  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算每个关键词的性别比例\n",
    "for keyword, filename in folder_dict.items():\n",
    "    filepath = os.path.join(exportfolder, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    # 将空值填充为'unknown'\n",
    "    df['gender_first'] = df['gender_first'].fillna('unknown')\n",
    "    df['gender_corresponding'] = df['gender_corresponding'].fillna('unknown')\n",
    "    df['gender_combination'] = df.apply(gender_combination, axis=1)\n",
    "    result = df['gender_combination'].value_counts()\n",
    "    results[keyword] = result\n",
    "    # 保存回原文件\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "# 转换为DataFrame并填充缺失值\n",
    "result_df = pd.DataFrame(results).fillna(0)\n",
    "\n",
    "# 按指定顺序排序列\n",
    "order = ['Male only', 'Male & Unknown', 'Both Unknown', 'Female only', 'Female & Unknown','Female & Male' ]\n",
    "result_df = result_df.reindex(order)\n",
    "\n",
    "# 显示结果\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0416",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
